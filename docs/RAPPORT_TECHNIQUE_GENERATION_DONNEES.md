# Rapport Technique : G√©n√©ration de Donn√©es Synth√©tiques pour GCP/Databricks

**Projet :** Pipeline de g√©n√©ration de donn√©es financi√®res synth√©tiques  
**Objectif :** 10M de transactions financi√®res (~2GB) pour analyse Databricks  
**Date de R√©daction :** 05 Juin 2025  
**Auteurs :** Sanda ANDRIA & Celia HADJI  
**Environnement :** GCP (Europe-West1), Python 3.12, Ubuntu WSL2

---

## üìã **Introduction et Contexte**

Bienvenue dans ce rapport technique ! Nous sommes Sanda ANDRIA et Celia HADJI, et nous allons vous pr√©senter le travail que nous avons accompli lors de notre premi√®re journ√©e sur le projet de g√©n√©ration de donn√©es synth√©tiques. L'objectif principal √©tait de mettre en place un pipeline robuste pour cr√©er un volume cons√©quent de donn√©es financi√®res (10 millions de lignes) destin√©es √† des analyses ult√©rieures sur Databricks.

Initialement, nous avions envisag√© une approche avec Apache Beam et Dataflow. Cependant, au fil de nos exp√©rimentations et des d√©fis rencontr√©s, nous avons pivot√© vers une solution locale optimis√©e en multi-threading. Ce changement s'est av√©r√© crucial, nous permettant de r√©duire drastiquement les temps de g√©n√©ration (de plus de 30 minutes √† seulement 3-5 minutes) tout en simplifiant la gestion des ressources cloud.

**Ce que nous avons accompli aujourd'hui :**
- ‚úÖ **Performance Am√©lior√©e** : G√©n√©ration de 10M lignes en 3-5 minutes.
- ‚úÖ **Fiabilit√© Accrue** : Taux de r√©ussite de 100% pour la g√©n√©ration.
- ‚úÖ **Optimisation des Co√ªts** : Suppression des co√ªts li√©s aux VMs Dataflow temporaires.
- ‚úÖ **Richesse des Donn√©es** : Cr√©ation de 19 types d'op√©rations financi√®res r√©alistes.

---

## üóìÔ∏è **D√©roulement de la Premi√®re Journ√©e de Travail (05/06/2025)**

Notre journ√©e a √©t√© rythm√©e par plusieurs phases cl√©s, allant de la configuration initiale de l'infrastructure √† l'optimisation finale du processus de g√©n√©ration.

### **Matin : Configuration & Premiers Tests avec Apache Beam/Dataflow**

#### **1. Mise en Place de l'Infrastructure GCP**

Nous avons commenc√© par d√©finir l'architecture cible de notre Data Lake sur Google Cloud Storage :

**Structure du Data Lake :**
```
gs://supdevinci_bucket/sanda_celia/
‚îú‚îÄ‚îÄ tmp/           # Fichiers temporaires pour Dataflow
‚îú‚îÄ‚îÄ raw/           # Donn√©es CSV brutes (notre output)
‚îú‚îÄ‚îÄ staging/       # Espace pour donn√©es optimis√©es (Parquet, via Databricks)
‚îî‚îÄ‚îÄ delta/         # Espace pour tables Delta finales (via Databricks)
```

Nous avons utilis√© les technologies suivantes :
- **Compute :** Google Cloud Dataflow (via Apache Beam)
- **Storage :** Google Cloud Storage
- **Analytics :** Databricks (pour la suite du projet)
- **IAM :** Un Service Account d√©di√© pour s√©curiser les acc√®s
- **R√©gion :** `europe-west1` pour √™tre en accord avec les normes RGPD.

La cr√©ation du Service Account s'est faite via gcloud :
```bash
gcloud iam service-accounts create dataflow-generator \
    --display-name="Dataflow Data Generator" \
    --description="Service account pour la g√©n√©ration de donn√©es"
```
Et nous lui avons attribu√© les r√¥les n√©cessaires : `roles/dataflow.admin`, `roles/dataflow.worker`, `roles/storage.admin`, et `roles/iam.serviceAccountUser`.

Le bucket GCS a √©galement √©t√© configur√© :
```bash
gsutil mb -p biforaplatform -l europe-west1 gs://supdevinci_bucket
```
Avec des politiques de cycle de vie pour g√©rer les fichiers temporaires et archiver les donn√©es.

#### **2. D√©veloppement du Pipeline Apache Beam Initial**

Ensuite, nous avons structur√© notre code pour le pipeline Apache Beam :
```
src/  # Ancien emplacement, maintenant simplifi√©
‚îú‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ generate_to_gcs.py  # Notre script Beam principal
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ data_generator.py
```

Le pipeline Beam √©tait con√ßu pour :
1. G√©n√©rer une s√©rie d'indices (`Create(range(1, 10_000_000))`).
2. Utiliser une transformation `DoFn` pour g√©n√©rer chaque ligne CSV avec sa logique m√©tier.
3. √âcrire les donn√©es sur GCS avec `WriteToText`, en shardant automatiquement les fichiers.

Nous avons impl√©ment√© la logique pour 19 types d'op√©rations financi√®res (cotisations, remboursements, provisions, etc.) avec des montants g√©n√©r√©s de mani√®re r√©aliste. Par exemple :
```python
def get_montant_by_operation_type(type_op: str) -> float:
    if type_op in ["cotisation", "prime_exceptionnelle"]:
        return round(random.uniform(50.0, 2500.0), 2)
    # ... et ainsi de suite pour les 19 types.
```

La configuration du pipeline incluait des param√®tres comme le nombre de shards, la taille cible et le type de machine pour les workers.

### **Apr√®s-midi : D√©fis, Debugging et Pivot Strat√©gique**

#### **3. Challenges Rencontr√©s avec Dataflow**

Rapidement, nous avons fait face √† plusieurs obstacles :

*   **Probl√®mes IAM Critiques :**
    L'erreur `constraints/dataflow.enforceComputeDefaultServiceAccountCheck` nous a bloqu√©s. Une politique organisationnelle nous emp√™chait d'utiliser le service account par d√©faut comme Dataflow le souhaitait. Les tentatives de modification de cette politique via `gcloud org-policies` ont √©chou√© faute de permissions suffisantes au niveau de l'organisation (notre projet n'ayant pas d'organisation parente directe).
    *   **R√©solution (partielle) :** Nous avons d√ª configurer manuellement les r√¥les via la console GCP, en ajoutant `roles/iam.serviceAccountUser` √† notre compte utilisateur et `roles/dataflow.worker` au service account, puis en sp√©cifiant explicitement ce dernier dans le code.

*   **√âpuisement des Ressources Compute :**
    L'erreur `ZONE_RESOURCE_POOL_EXHAUSTED` dans `europe-west1-d` √©tait fr√©quente. Apr√®s investigation, nous avons constat√© que trois grosses instances Databricks (`n2-highmem-4`) monopolisaient les ressources de cette zone.
    *   **Solutions test√©es :**
        1.  Arr√™ter les instances Databricks pour lib√©rer les ressources :
            ```bash
            gcloud compute instances stop databricks-* --zone=europe-west1-d --discard-local-ssd=false
            ```
        2.  Modifier la `worker_zone` du pipeline Dataflow pour `europe-west1-c`.
        3.  Utiliser des `worker_machine_type` plus petits comme `n1-standard-1`.

*   **Difficult√©s avec les D√©pendances et Imports :**
    Des `ModuleNotFoundError` (par exemple, pour `generate_to_gcs`) sont apparus. Ces erreurs √©taient dues √† des incompatibilit√©s entre les imports relatifs de notre structure de projet locale et la mani√®re dont Dataflow ex√©cute le code sur ses workers, ainsi qu'√† des conflits de versions de d√©pendances.
    *   **Solutions appliqu√©es (pour Dataflow) :** Nous avons d√ª unifier le code en un seul fichier, √©liminer les imports relatifs et synchroniser les versions des d√©pendances (ex: `faker==19.13.0`, `apache-beam[gcp]==2.65.0`).

#### **4. Vers une Solution Optimis√©e : G√©n√©ration Locale Multi-Thread**

Face √† ces d√©fis persistants avec Dataflow (temps de d√©marrage longs, gestion complexe des d√©pendances et des ressources pour notre cas d'usage somme toute simple de g√©n√©ration de CSV), nous avons d√©cid√© d'explorer une alternative.

*   **Analyse Critique de Dataflow pour ce Cas :**
    L'overhead de Dataflow (5-10 minutes juste pour le setup des VMs et des d√©pendances) et la complexit√© du scaling automatique n'√©taient pas justifi√©s. Le rapport co√ªt/performance n'√©tait pas optimal. Un benchmark rapide nous a montr√© que Dataflow prenait plus de 30 minutes pour la t√¢che (quand il ne rencontrait pas d'erreur).

*   **Conception de la Solution Alternative :**
    Nous avons opt√© pour un script Python local utilisant le multi-threading (`ThreadPoolExecutor`) pour g√©n√©rer les donn√©es en parall√®le.
    ```python
    # Exemple de configuration pour 12 CPUs
    NUM_THREADS = 10          # Utilisation √† ~83% des CPUs
    CHUNK_SIZE = 250_000      # Bon √©quilibre m√©moire/performance
    NUM_FILES = 5             # Pour parall√©liser l'upload avec gsutil
    ```
    Le pipeline simplifi√© est devenu :
    1.  G√©n√©ration parall√®le des lignes par plusieurs threads.
    2.  √âcriture directe des fichiers CSV finaux (sans consolidation interm√©diaire complexe).
    3.  Upload parall√®le vers GCS en utilisant `gsutil -m cp`.

*   **Impl√©mentation et Debugging Final :**
    La fonction de g√©n√©ration a √©t√© adapt√©e :
    ```python
    def generate_file_direct(file_index: int, rows_per_file: int) -> str:
        with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile, quoting=csv.QUOTE_MINIMAL)
            # ... logique de g√©n√©ration ...
    ```
    L'upload s'est simplifi√© √† :
    ```python
    cmd = ["gsutil", "-m", "cp"] + local_files + [gcs_destination]
    subprocess.run(cmd, check=True)
    ```
    Un dernier souci d'encodage UTF-8 (erreur `byte 0xc3`) a √©t√© r√©solu en :
    1.  Simplifiant les donn√©es g√©n√©r√©es (ex: "sant√©" ‚Üí "sante").
    2.  For√ßant l'encodage `utf-8` partout.
    3.  Convertissant explicitement les montants en `str()`.
    4.  G√©n√©rant directement les fichiers finaux, √©liminant une √©tape de consolidation source d'erreurs.

---

## üìä **R√©sultats de la Journ√©e et Comparaison des Performances**

Cette r√©orientation strat√©gique a port√© ses fruits de mani√®re spectaculaire.

### **M√©triques de Performance Cl√©s**

| **M√©thode**              | **Temps Total** | **Fiabilit√©**             | **Co√ªt GCP**      | **Complexit√©** |
| ------------------------ | --------------- | ------------------------- | ----------------- | -------------- |
| **Apache Beam/Dataflow** | 30+ min         | ~60% (erreurs fr√©quentes) | ‚Ç¨5-10/run         | √âlev√©e         |
| **Multi-thread local**   | **3-5 min**     | **100%**                  | ‚Ç¨0 (storage seul) | **Faible**     |

Cela repr√©sente une **am√©lioration de performance de 600 √† 1000%** !

### **Qualit√© et Scalabilit√© des Donn√©es**

Les donn√©es g√©n√©r√©es sont conformes √† nos attentes :
```csv
id_mouvement,date_op,produit,type_op,montant,agence_id,pays
M0000001,2025-06-06,auto,provision_sinistre,8944.6,AG_007,FR
M0000002,2025-06-15,sante,cotisation,1250.75,AG_012,ES
```
Avec une distribution r√©aliste des 19 types d'op√©rations.

La solution locale est √©galement scalable :
-   **10M lignes :** 3-5 minutes.
-   **50M lignes :** Estim√© √† 15-20 minutes.
-   **100M lignes :** Probablement r√©alisable en moins d'une heure sur une machine de d√©veloppement correcte.
    Les limites principales sont le disque local, la bande passante pour l'upload, et les ressources CPU/RAM de la machine ex√©cutant le script.

---

## üîß **Automatisation et Organisation du Projet**

Pour p√©renniser notre travail, nous avons mis en place une infrastructure as code avec Terraform et organis√© notre projet.

### **Infrastructure Terraform**

Un ensemble de fichiers Terraform (`infrastructure/terraform/main.tf`) de plus de 200 lignes permet de d√©ployer automatiquement :
-   Le service account `dataflow-generator` avec les bonnes permissions.
-   Les r√¥les IAM n√©cessaires.
-   L'activation des APIs GCP (Dataflow, Storage, etc.).
-   La structure de dossiers sur GCS.
-   La gestion des politiques d'organisation probl√©matiques.
-   Des r√®gles de cycle de vie pour optimiser les co√ªts de stockage.

Un script `scripts/deploy.sh` orchestre ce d√©ploiement.

### **Documentation et Maintenance**
Nous avons structur√© le projet avec des dossiers clairs (`docs/`, `src/`, `scripts/`, `infrastructure/`) et cr√©√© plusieurs documents de support :
-   `README.md` : Guide d'utilisation principal.
-   `docs/GCP_GCLOUD_CHEATSHEET.md` : Aide-m√©moire des commandes gcloud.
-   Ce `docs/RAPPORT_TECHNIQUE_GENERATION_DONNEES.md`.

---

## üöÄ **Recommandations et Prochaines √âtapes (Pour la Suite)**

Forts de cette premi√®re journ√©e intense, voici quelques recommandations pour la suite du projet et pour des contextes similaires.

### **Recommandations Techniques Imm√©diates**

1.  **√âvaluer la Complexit√© vs. Solution :** Toujours se demander si un outil puissant comme Dataflow est r√©ellement n√©cessaire pour la t√¢che √† accomplir.
2.  **Simplicit√© d'Abord :** Privil√©gier les solutions simples et locales lorsque c'est possible, surtout pour la g√©n√©ration de donn√©es ou des ETLs basiques.
3.  **Tests Locaux Approfondis :** Tester autant que possible localement avant de d√©ployer sur le cloud.
4.  **Vigilance IAM :** Les politiques IAM, surtout dans des environnements avec des contraintes organisationnelles, peuvent √™tre un frein majeur.

Pour la g√©n√©ration de donn√©es, nous sugg√©rons les seuils suivants comme point de d√©part :
-   **< 50M lignes :** Notre solution multi-thread locale est id√©ale.
-   **50M-500M lignes :** Envisager Cloud Run ou des instances Compute Engine d√©di√©es.
-   **> 500M lignes :** Dataflow ou Spark deviennent alors plus pertinents.

### **√âvolutions Futures pour Ce Projet**
-   Support de formats de sortie multiples (Parquet, Avro) directement depuis le g√©n√©rateur local.
-   Peut-√™tre une petite interface web pour configurer les param√®tres de g√©n√©ration.
-   Int√©gration plus pouss√©e avec Databricks (d√©clenchement automatique post-upload, conversion Parquet/Delta).

### **Principaux Enseignements de la Journ√©e**
1.  **La simplicit√© peut surpasser la complexit√© :** Notre script local est bien plus performant et fiable que Dataflow pour ce cas.
2.  **Les contraintes IAM organisationnelles sont un vrai d√©fi.**
3.  **La gestion des imports Python par Dataflow est d√©licate.**
4.  **La disponibilit√© des ressources dans les zones GCP est un facteur √† ne pas n√©gliger.**

---

## üìà **Conclusion de Notre Premi√®re Journ√©e**

Cette premi√®re journ√©e de travail a √©t√© riche en apprentissages. Nous avons r√©ussi √† mettre en place un syst√®me de g√©n√©ration de donn√©es synth√©tiques non seulement fonctionnel mais aussi extr√™mement performant et fiable, en adaptant notre approche face aux d√©fis rencontr√©s.

**Nos succ√®s du jour :**
-   ‚úÖ Objectif de 10M lignes atteint.
-   ‚úÖ Performance multipli√©e par 10 par rapport √† notre id√©e initiale.
-   ‚úÖ Fiabilit√© de 100% pour la g√©n√©ration.
-   ‚úÖ Infrastructure reproductible gr√¢ce √† Terraform.

L'impact est significatif : un temps de g√©n√©ration r√©duit de plus de 30 minutes √† moins de 5 minutes, des co√ªts cloud ma√Ætris√©s, et une meilleure fiabilit√© op√©rationnelle. Cette base solide nous permettra d'aborder sereinement les prochaines √©tapes du projet, notamment l'int√©gration avec Databricks.

---

**R√©dig√© par :** Sanda ANDRIA & Celia HADJI  
**Date :** 05 Juin 2025 